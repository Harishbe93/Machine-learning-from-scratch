{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to K-NN:\n",
    "The k-Nearest Neighbors algorithm or KNN for short is a very simple technique.\n",
    "\n",
    "The entire training dataset is stored. When a prediction is required, the k-most similar records to a new record from the training dataset are then located. From these neighbors, a summarized prediction is made.\n",
    "\n",
    "Similarity between records can be measured many different ways. A problem or data-specific method can be used. Generally, with tabular data, a good starting point is the Euclidean distance.\n",
    "\n",
    "Once the neighbors are discovered, the summary prediction can be made by returning the most common outcome or taking the average. As such, KNN can be used for classification or regression problems.\n",
    "\n",
    "There is no model to speak of other than holding the entire training dataset. Because no work is done until a prediction is required, KNN is often referred to as a lazy learning method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from random import seed, randrange\n",
    "from csv import reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(row1, row2):\n",
    "    \"\"\"\n",
    "    Calculates the distance between any two records\n",
    "    ###Input###\n",
    "        row1 -> A row from the training data\n",
    "        row2 -> A row from the test data\n",
    "    ###Output###\n",
    "        sqrt(dist) -> Returns the distance between the rows\n",
    "    \"\"\"\n",
    "    dist = 0.0\n",
    "    for i in range(len(row1) - 1): # Assuming last column being the target, excluding it\n",
    "        dist += (row1[i] - row2[i])**2\n",
    "    return sqrt(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbours(train, test_row, num_neighbours):\n",
    "    \"\"\"\n",
    "    Calculates the required number of neighbours for a given test row\n",
    "    ###Input### \n",
    "        train -> The entire training dataset\n",
    "        test_row -> A row from the test dataset\n",
    "        num_neighbours -> Number of neighbours we need\n",
    "    ###Output### \n",
    "        neighbours -> Returns the neighbours for a given test row\n",
    "    \"\"\"\n",
    "    distances = list()\n",
    "    for train_row in train:\n",
    "        dist = euclidean_distance(train_row, test_row)\n",
    "        distances.append((train_row, dist))\n",
    "    distances.sort(key = lambda x: x[1])\n",
    "    neighbours = list()\n",
    "    for i in range(num_neighbours):\n",
    "        neighbours.append(distances[i][0])\n",
    "    return neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(train, test_row, num_neighbours):\n",
    "    \"\"\"\n",
    "    Determines the target class for a given test row\n",
    "    ###Input### \n",
    "        train -> The entire training dataset\n",
    "        test_row -> A row from the test dataset\n",
    "        num_neighbours -> Number of neighbours we need\n",
    "    ###Output### \n",
    "        prediction -> Returns the target class for a given test row\n",
    "    \"\"\"\n",
    "    neighbours = get_neighbours(train, test_row, num_neighbours)\n",
    "    outputs = [row[-1] for row in neighbours]\n",
    "    prediction = max(set(outputs),key = outputs.count)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(filename):\n",
    "    \"\"\"\n",
    "    Loads the .csv file\n",
    "    ###Input### \n",
    "        filename -> Name of the .csv file to be loaded\n",
    "    ###Output### \n",
    "        dataset -> Returns the .csv file in the form of a python list\n",
    "    \"\"\"\n",
    "    dataset = []\n",
    "    with open(filename,\"r\") as file:\n",
    "        csv_reader = reader(file)\n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            dataset.append(row)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_column_to_float(dataset, column):\n",
    "    \"\"\"\n",
    "    Changes the numeric column which is stored as strings to float dtype\n",
    "    ###Input### \n",
    "        dataset -> The dataset containing the column\n",
    "        column -> Index of the column which contains the numbers (stored as strings)\n",
    "    ###Output### \n",
    "        None -> It changes the dtype of the column in the original dataset itself\n",
    "    \"\"\"\n",
    "    for row in dataset:\n",
    "        row[column] = float(row[column].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_column_to_int(dataset, column):\n",
    "    \"\"\"\n",
    "    Performs the label encoding\n",
    "    ###Input### \n",
    "        dataset -> The dataset containing the column\n",
    "        column -> Index of the column which contains the categories\n",
    "    ###Output### \n",
    "        None -> It replaces the categories in a column to its numeric equivalent in the original dataset itself\n",
    "    \"\"\"\n",
    "    classes = [row[column] for row in dataset]\n",
    "    unique = set(classes)\n",
    "    lookup = {}\n",
    "    for i,value in enumerate(unique):\n",
    "        lookup[value] = i\n",
    "    print(lookup)\n",
    "    for row in dataset:\n",
    "        row[column] = lookup[row[column]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_minmax(dataset):\n",
    "    \"\"\"\n",
    "    Calculates the min and max values of all the columns\n",
    "    ###Input### \n",
    "        dataset -> The entire dataset that needs to be scaled\n",
    "    ###Output### \n",
    "        minmax -> A dictionary containing the min and max values of all the columns indexed \n",
    "                  by the column position\n",
    "    \"\"\"\n",
    "    minmax = []\n",
    "    for i in range(len(dataset[0])):\n",
    "        col_values = [row[i] for row in dataset]\n",
    "        min_val = min(col_values)\n",
    "        max_val = max(col_values)\n",
    "        minmax.append([min_val,max_val])\n",
    "    return minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataset(dataset, minmax):\n",
    "    \"\"\"\n",
    "    Performs the min-max normalization\n",
    "    ###Input### \n",
    "        dataset -> The entire dataset that needs to be scaled\n",
    "        minmax -> A dictionary containing the min and max values of all the columns indexed \n",
    "                  by the column position\n",
    "    ###Output### \n",
    "        None -> It scales the dataset based on the minmax dictionary (Range of values : 0-1)\n",
    "    \"\"\"\n",
    "    for col in range(len(dataset[0])):\n",
    "        for row in dataset:\n",
    "            row[col] = (row[col] - minmax[col][0])/(minmax[col][1] - minmax[col][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_split(dataset, nfolds):\n",
    "    \"\"\"\n",
    "    Performs the splitting of the dataset into \"nfolds\" folds\n",
    "    ###Input### \n",
    "        dataset -> The entire dataset that needs to be scaled\n",
    "        nfolds -> Number of folds to be used for cross validation\n",
    "    ###Output### \n",
    "        dataset_split -> A list containing \"nfolds\" folds to be used for cross validation\n",
    "    \"\"\"\n",
    "    dataset_split = []\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset)/nfolds)\n",
    "    for _ in range(nfolds):\n",
    "        fold = []\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_metric(actuals, predictions):\n",
    "    \"\"\"\n",
    "    Calculates the accuracy of the predictions\n",
    "    ###Input### \n",
    "        actuals -> Actual target values\n",
    "        predictions -> Predicted target values\n",
    "    ###Output### \n",
    "        acc -> Returns the accuracy of the predictions\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    for i in range(len(actuals)):\n",
    "        if actuals[i] == predictions[i]:\n",
    "            correct += 1\n",
    "    acc = (correct/len(actuals)) * 100.0\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_algorithm(dataset, algorithm, nfolds, *args):\n",
    "    \"\"\"\n",
    "    Evaluates any algorithm using the K-fold cross validation technique\n",
    "    ###Input### \n",
    "        dataset -> Input dataset\n",
    "        algorithm -> Function that performs K-NN and returns predictions\n",
    "        nfolds -> Number of folds to be used in cross validation\n",
    "        *args -> Variable number of arguments to be used in the function, if needed\n",
    "    ###Output### \n",
    "        scores -> Returns a list of scores on the different folds used\n",
    "    \"\"\"\n",
    "    folds = cross_validation_split(dataset, nfolds)\n",
    "    print(len(folds))\n",
    "    scores = []\n",
    "    for fold in folds:\n",
    "        train_set = list(folds)\n",
    "        train_set.remove(fold)\n",
    "        train_set = sum(train_set,[])\n",
    "        test_set = list(fold)\n",
    "        predictions = algorithm(train_set, test_set, *args)\n",
    "        actuals = [row[-1] for row in test_set]\n",
    "        accuracy = accuracy_metric(actuals, predictions)\n",
    "        scores.append(accuracy)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNN(train_set, test_set, num_neighbours):\n",
    "    \"\"\"\n",
    "    Performs K-NN classification by putting all the functions defined earlier together\n",
    "    ###Input### \n",
    "        train_set -> training dataset\n",
    "        test_set -> test dataset\n",
    "        num neighbours -> Number of neighbours we need\n",
    "    ###Output### \n",
    "        predictions -> Returns the predictions for the test set\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    for row in test_set:\n",
    "        prediction = predict_class(train_set, row, num_neighbours)\n",
    "        predictions.append(prediction)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\s5rxcy'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Versicolor': 0, 'Virginica': 1, 'Setosa': 2}\n",
      "Data=[4.5, 2.3, 1.3, 0.3], Predicted: 2\n"
     ]
    }
   ],
   "source": [
    "seed(1)\n",
    "filename = 'iris.csv'\n",
    "dataset = load_csv(filename)\n",
    "dataset = dataset[1:]\n",
    "for i in range(len(dataset[0])-1):\n",
    "    str_column_to_float(dataset, i)\n",
    "# convert class column to integers\n",
    "str_column_to_int(dataset, len(dataset[0])-1)\n",
    "# define model parameter\n",
    "num_neighbors = 5\n",
    "# define a new record\n",
    "row = [4.5, 2.3, 1.3, 0.3]\n",
    "# predict the label\n",
    "label = predict_class(dataset, row, num_neighbors)\n",
    "print('Data=%s, Predicted: %s' % (row, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Scores: [96.66666666666667, 100.0, 96.66666666666667, 96.66666666666667, 96.66666666666667]\n",
      "Mean Accuracy: 97.333%\n"
     ]
    }
   ],
   "source": [
    "n_folds = 5\n",
    "num_neighbors = 5\n",
    "scores = evaluate_algorithm(dataset, kNN, n_folds, num_neighbors)\n",
    "print('Scores: %s' % scores)\n",
    "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check our output with the sklearn's implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width variety\n",
       "0           5.1          3.5           1.4          0.2  Setosa\n",
       "1           4.9          3.0           1.4          0.2  Setosa\n",
       "2           4.7          3.2           1.3          0.2  Setosa\n",
       "3           4.6          3.1           1.5          0.2  Setosa\n",
       "4           5.0          3.6           1.4          0.2  Setosa"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {'Setosa': 0, 'Versicolor': 1, 'Virginica': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris[\"variety\"] = iris[\"variety\"].map(class_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal.length    float64\n",
       "sepal.width     float64\n",
       "petal.length    float64\n",
       "petal.width     float64\n",
       "variety           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifier = KNeighborsClassifier(n_neighbors=5, metric = 'euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_classifier.fit(iris.drop(\"variety\",axis = 1), iris[\"variety\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = knn_classifier.predict(iris.drop(\"variety\",axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.66666666666667"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_metric(iris.variety, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(knn_classifier, iris.drop(\"variety\",axis = 1), iris[\"variety\"], cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 1.        , 0.93333333, 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9733333333333334"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation scores are a bit different because of the fact that different set of records being taken into different folds in two different cross validation techniques and by the tie-breaking mechanism between the two implementations"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
